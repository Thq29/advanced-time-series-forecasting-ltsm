# Advanced Time Series Forecasting with Deep Learning and Explainability

This project implements an end-to-end multivariate time series forecasting pipeline using LSTM and Transformer models. It includes rolling-origin cross-validation, uncertainty quantification, and model explainability using SHAP or Integrated Gradients. The system is designed to be production-ready with clean structure, documentation, and insights.

## ğŸš€ Project Features

### 1. Data Preparation
- Handles multivariate time series datasets
- Normalization, scaling, and missing value handling
- Creation of lag features and exogenous regressors
- Rolling-origin train/validation splits

### 2. Forecasting Models
- LSTM-based deep learning model
- Transformer encoder model for long-range dependencies
- Hyperparameter tuning with rolling-origin evaluation

### 3. Uncertainty Quantification
- Quantile regression (0.1, 0.5, 0.9)
- OR Monte Carlo Dropout for probabilistic forecasting

### 4. Explainability
- SHAP values for feature/time-step importance
- Integrated Gradients for deep model attribution
- Insights about which features drive predictions

### 5. Evaluation Metrics
- MAE
- RMSE
- SMAPE
- MASE
- Prediction interval coverage
- Rolling-origin validation error curves

## ğŸ“Š Project Structure
.  
â”œâ”€â”€ main.py                # Main pipeline execution  
â”œâ”€â”€ data/                  # Dataset (not included)  
â”œâ”€â”€ models/                # LSTM/Transformer models  
â”œâ”€â”€ preprocessing/         # Scaling + feature engineering  
â”œâ”€â”€ utils/                 # Helpers, metrics, plotting  
â”œâ”€â”€ explainability/        # SHAP / Integrated Gradients  
â”œâ”€â”€ report.md              # Full analysis report  
â””â”€â”€ README.md              # This file  

## ğŸ§ª How to Run
1. Install dependencies:  
pip install -r requirements.txt  

2. Run the pipeline:  
python main.py  

3. Results will be saved in the outputs folder (plots, metrics, explainability charts).

## ğŸ“ˆ Results Summary
The project outputs:
- Forecast visualizations  
- Uncertainty bands (quantile intervals)  
- Evaluation metrics table  
- SHAP/IG explainability charts  
- Analysis of which features/time steps influence predictions the most  

## ğŸ“ Report
See report.md for:
- Dataset description  
- Model architecture  
- Cross-validation results  
- Explainability insights  
- Final conclusions  

## ğŸ“œ License
MIT License.
